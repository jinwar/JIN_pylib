{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70c55b6",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c142e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frequency_downsample = 10\n",
    "temporal_resolution = 10\n",
    "output_path = './output'\n",
    "\n",
    "import os\n",
    "from JIN_pylib import gjsignal, ProcessUtil\n",
    "from JIN_pylib import Data3D_XTF\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "\n",
    "if os.path.exists(output_path) is False:\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "\n",
    "time_segments = sub_sp.get_chunks(temporal_resolution,is_partial=False)\n",
    "data_collector = []\n",
    "data_size = 0\n",
    "data_io_time = 0\n",
    "data_process_time = 0\n",
    "\n",
    "def save_file(data_collector, output_path):\n",
    "    data = Data3D_XTF.Data3D()\n",
    "    # make sure all data segments have the same length\n",
    "    data_length = np.array([d.data.shape[1] for d in data_collector])\n",
    "    median_length = np.median(data_length)\n",
    "    for i, d in enumerate(data_collector):\n",
    "        if d.data.shape[1] < median_length:\n",
    "            padding = np.zeros((d.data.shape[0], int(median_length - d.data.shape[1])))\n",
    "            d.data = np.hstack((d.data, padding))\n",
    "        elif d.data.shape[1] > median_length:\n",
    "            d.data = d.data[:, :int(median_length)]\n",
    "    # Now all data segments should have the same length\n",
    "    data.data = np.array([d.data for d in data_collector])\n",
    "    data.start_time = data_collector[0].start_time\n",
    "    data.taxis = np.array([(d.start_time - data.start_time).total_seconds() for d in data_collector])\n",
    "    data.faxis = data_collector[0].taxis\n",
    "    data.daxis = data_collector[0].daxis\n",
    "    output_file = os.path.join(output_path, f'SPEdata_{data.start_time.strftime(\"%Y%m%d_%H%M%S\")}.h5')\n",
    "    data.saveh5(output_file)\n",
    "    print(f'Saved data to {output_file}')\n",
    "    return output_file\n",
    "\n",
    "for time_seg in tqdm(time_segments):\n",
    "    bgt, edt = time_seg\n",
    "    tic = time()\n",
    "    DASdata = sub_sp.get_data(bgt, edt)\n",
    "    toc = time()\n",
    "    data_io_time += toc - tic\n",
    "\n",
    "    tic = time()\n",
    "\n",
    "    data = DASdata.data\n",
    "    N = data.shape[1]// frequency_downsample\n",
    "    fftdata = 0\n",
    "    for i in range(frequency_downsample):\n",
    "        fftdata += np.abs(np.fft.rfft(data[:, i*N:(i+1)*N], axis=1))\n",
    "\n",
    "    dt = np.median(np.diff(DASdata.taxis)) \n",
    "    freq = np.fft.rfftfreq(N, dt)\n",
    "\n",
    "    SPEdata = DASdata\n",
    "    SPEdata.data = fftdata\n",
    "    SPEdata.taxis = freq\n",
    "    SPEdata.start_time = DASdata.start_time + timedelta(seconds = DASdata.taxis[-1]/2)\n",
    "\n",
    "    # SPEdata = ProcessUtil.spectrum_transform_2D(DASdata)\n",
    "    # SPEdata.start_time = DASdata.start_time + timedelta(seconds = DASdata.taxis[-1]/2)\n",
    "    # N = SPEdata.data.shape[1]\n",
    "    # N = np.floor(N/frequency_downsample).astype(int)*frequency_downsample\n",
    "    # SPEdata.data = SPEdata.data[:, :N]\n",
    "    # SPEdata.data = SPEdata.data.reshape(SPEdata.data.shape[0], -1, frequency_downsample).mean(axis=2)\n",
    "    # SPEdata.taxis = SPEdata.taxis[:N]\n",
    "    # SPEdata.taxis = SPEdata.taxis.reshape(-1, frequency_downsample).mean(axis=1)\n",
    "\n",
    "\n",
    "    toc = time()\n",
    "    data_process_time += toc - tic\n",
    "\n",
    "    data_collector.append(SPEdata)\n",
    "    data_size += SPEdata.data.size\n",
    "\n",
    "    if data_size > 1e8:\n",
    "        output_file = save_file(data_collector, output_path)\n",
    "        data_size = 0\n",
    "        data_collector = []\n",
    "\n",
    "if len(data_collector) > 0:\n",
    "    output_file = save_file(data_collector, output_path)\n",
    "\n",
    "print(f'Data IO time: {data_io_time:.2f} s')\n",
    "print(f'Data processing time: {data_process_time:.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7266d",
   "metadata": {},
   "source": [
    "# FBA processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884523e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from JIN_pylib import Data3D_XTF, Data2D_XT\n",
    "from tqdm import tqdm\n",
    "\n",
    "files = glob('./output/*.h5')\n",
    "\n",
    "freq_min = 10\n",
    "freq_max = 200\n",
    "\n",
    "FBAdata = Data3D_XTF.get_FBA_from_files(files, freq_min, freq_max)\n",
    "FBAdata.fill_gap_zeros()\n",
    "FBAdata.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f62fb8",
   "metadata": {},
   "source": [
    "# Channel Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa2ef61",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
